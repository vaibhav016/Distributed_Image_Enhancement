{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, Input, regularizers\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, UpSampling2D, Add, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split \n",
    "import pickle\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52001\n"
     ]
    }
   ],
   "source": [
    "path_file = 'archive/*png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will pixelate the image for faces\n",
    "def load_image_train(image_file):\n",
    "    # Read and decode an image file to a uint8 tensor\n",
    "    image = tf.io.read_file(image_file)\n",
    "    image = tf.io.decode_jpeg(image)\n",
    "\n",
    "    # Convert images to float32 tensors\n",
    "    input_image = tf.cast(image, tf.float32)\n",
    "    input_image = tf.image.resize(input_image, [IMG_HEIGHT, IMG_WIDTH],\n",
    "                                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    input_image = tf.cast(input_image, tf.float32) / 255.0 \n",
    "    \n",
    "    #Obtain pixelated image\n",
    "    width = int(input_image.shape[1] * scale_percent / 100)\n",
    "    height = int(input_image.shape[0] * scale_percent / 100)\n",
    "    \n",
    "    small_image = tf.image.resize(input_image, [height, width],\n",
    "                                method=tf.image.ResizeMethod.AREA)\n",
    "\n",
    "    pixelated_image = tf.image.resize(small_image, [IMG_HEIGHT, IMG_WIDTH],\n",
    "                                method=tf.image.ResizeMethod.AREA)\n",
    "   \n",
    "\n",
    "    return input_image, pixelated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(global_batch):\n",
    "    BUFFER_SIZE = 400\n",
    "    # The batch size of 1 produced better results for the U-Net in the original pix2pix experiment\n",
    "    BATCH_SIZE = 1\n",
    "    # Each image is 256x256 in size\n",
    "    IMG_WIDTH = 200\n",
    "    IMG_HEIGHT = 200\n",
    "    scale_percent = 30\n",
    "#     path = \"BD_project/lfw/*/*.jpg\"\n",
    "    path = 'archive/*.png'\n",
    "\n",
    "    \n",
    "    # We will pixelate the image for faces\n",
    "    def load_image_train(image_file):\n",
    "        # Read and decode an image file to a uint8 tensor\n",
    "        image = tf.io.read_file(image_file)\n",
    "        image = tf.io.decode_jpeg(image)\n",
    "\n",
    "        # Convert images to float32 tensors\n",
    "        input_image = tf.cast(image, tf.float32)\n",
    "        input_image = tf.image.resize(input_image, [IMG_HEIGHT, IMG_WIDTH],\n",
    "                                    method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "        input_image = tf.cast(input_image, tf.float32) / 255.0 \n",
    "\n",
    "        #Obtain pixelated image\n",
    "        width = int(input_image.shape[1] * scale_percent / 100)\n",
    "        height = int(input_image.shape[0] * scale_percent / 100)\n",
    "\n",
    "        small_image = tf.image.resize(input_image, [height, width],\n",
    "                                    method=tf.image.ResizeMethod.AREA)\n",
    "\n",
    "        pixelated_image = tf.image.resize(small_image, [IMG_HEIGHT, IMG_WIDTH],\n",
    "                                    method=tf.image.ResizeMethod.AREA)\n",
    "\n",
    "\n",
    "        return input_image, pixelated_image\n",
    "    \n",
    "    train_dataset = tf.data.Dataset.list_files(path)\n",
    "    train_dataset = train_dataset.map(load_image_train,\n",
    "                                      num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
    "    train_dataset = train_dataset.batch(global_batch)\n",
    "    \n",
    "    return train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import auto\n",
    "def build_and_compile_latent_model():\n",
    "    #with strategy.scope():\n",
    "    Input_img = Input(shape=(None, None, 3))  \n",
    "\n",
    "    #encoding architecture\n",
    "    x1 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(Input_img)\n",
    "    x2 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(x1)\n",
    "    x3 = MaxPool2D(padding='same')(x2)\n",
    "\n",
    "    x4 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(x3)\n",
    "    x5 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(x4)\n",
    "    x6 = MaxPool2D(padding='same')(x5)\n",
    "\n",
    "    encoded = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(x6)\n",
    "    #encoded = Conv2D(64, (3, 3), activation='relu', padding='same')(x2)\n",
    "\n",
    "    # decoding architecture\n",
    "    x7 = UpSampling2D()(encoded)\n",
    "    x8 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(x7)\n",
    "    x9 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(x8)\n",
    "    x10 = Add()([x5, x9])\n",
    "\n",
    "    x11 = UpSampling2D()(x10)\n",
    "    x12 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(x11)\n",
    "    x13 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(x12)\n",
    "    x14 = Add()([x2, x13])\n",
    "\n",
    "    # x3 = UpSampling2D((2, 2))(x3)\n",
    "    # x2 = Conv2D(128, (3, 3), activation='relu', padding='same')(x3)\n",
    "    # x1 = Conv2D(256, (3, 3), activation='relu', padding='same')(x2)\n",
    "    decoded = Conv2D(1, (3, 3), padding='same',activation='relu', kernel_regularizer=regularizers.l1(10e-10))(x14)\n",
    "\n",
    "    autoencoder = Model(Input_img, decoded)\n",
    "    autoencoder.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "4V42bB52SwK2"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def train_func_distributed():\n",
    "    per_worker_batch_size = 8\n",
    "    # This environment variable will be set by Ray Train.\n",
    "    tf_config = json.loads(os.environ['TF_CONFIG'])\n",
    "    num_workers = len(tf_config['cluster']['worker'])\n",
    "\n",
    "    strategy = tf.distribute.MultiWorkerMirroredStrategy()\n",
    "\n",
    "    global_batch_size = per_worker_batch_size * num_workers\n",
    "    multi_worker_dataset = make_data(global_batch_size)\n",
    "\n",
    "    with strategy.scope():\n",
    "        # Model building/compiling need to be within `strategy.scope()`.\n",
    "        multi_worker_model = build_and_compile_latent_model()\n",
    "\n",
    "    multi_worker_model.fit(multi_worker_dataset, epochs=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x5T3SNM6o9j2",
    "outputId": "2976cb9b-0f90-4f54-9771-6c0f7eb8afaf",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-08 14:39:02,967\tINFO trainer.py:199 -- Trainer logs will be logged in: /Users/vaibhavsingh/ray_results/train_2022-04-08_14-39-02\n",
      "2022-04-08 14:39:03,902\tINFO trainer.py:205 -- Run results will be logged in: /Users/vaibhavsingh/ray_results/train_2022-04-08_14-39-02/run_001\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m 2022-04-08 14:39:10.632824: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m 2022-04-08 14:39:10.636237: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> 127.0.0.1:56763}\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m 2022-04-08 14:39:10.636359: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:437] Started server with target: grpc://127.0.0.1:56763\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function make_data.<locals>.load_image_train at 0x7fcc6ed8df70> and will run it as-is.\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m Cause: Unknown node type <gast.gast.Import object at 0x7fcc5117a760>\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m 2022-04-08 14:39:11.256059: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_1\"\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m op: \"TensorSliceDataset\"\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m input: \"Placeholder/_0\"\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m attr {\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m   key: \"Toutput_types\"\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m   value {\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m     list {\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m       type: DT_STRING\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m     }\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m   }\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m }\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m attr {\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m   key: \"_cardinality\"\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m   value {\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m     i: 52001\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m   }\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m }\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m attr {\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m   key: \"is_files\"\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m   value {\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m     b: false\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m   }\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m }\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m attr {\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m   key: \"metadata\"\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m   value {\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m     s: \"\\n\\024TensorSliceDataset:0\"\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m   }\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m }\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m attr {\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m   key: \"output_shapes\"\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m   value {\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m     list {\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m       shape {\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m       }\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m     }\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m   }\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m }\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m experimental_type {\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m   type_id: TFT_PRODUCT\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m   args {\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m     type_id: TFT_DATASET\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m     args {\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m       type_id: TFT_PRODUCT\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m       args {\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m         type_id: TFT_TENSOR\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m         args {\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m           type_id: TFT_STRING\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m         }\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m       }\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m     }\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m   }\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m   args {\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m     type_id: TFT_DATASET\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m     args {\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m       type_id: TFT_PRODUCT\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m       args {\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m         type_id: TFT_TENSOR\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m         args {\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m           type_id: TFT_STRING\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m         }\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m       }\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m     }\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m   }\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m }\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m \n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m 2022-04-08 14:39:11.297749: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=20621)\u001b[0m Epoch 1/3\n",
      "   1/6501 [..............................] - ETA: 11:45:00 - loss: 0.2503 - accuracy: 0.0013\n",
      "   2/6501 [..............................] - ETA: 7:59:57 - loss: 0.1340 - accuracy: 6.8854e-04\n",
      "   3/6501 [..............................] - ETA: 7:12:33 - loss: 0.1250 - accuracy: 0.0027    \n",
      "   4/6501 [..............................] - ETA: 6:49:11 - loss: 0.0989 - accuracy: 0.0029\n",
      "   5/6501 [..............................] - ETA: 6:42:24 - loss: 0.0893 - accuracy: 0.0024\n",
      "   6/6501 [..............................] - ETA: 6:34:01 - loss: 0.0771 - accuracy: 0.0022\n",
      "   7/6501 [..............................] - ETA: 6:27:14 - loss: 0.0676 - accuracy: 0.0020\n",
      "   8/6501 [..............................] - ETA: 6:22:08 - loss: 0.0608 - accuracy: 0.0018\n",
      "   9/6501 [..............................] - ETA: 6:17:34 - loss: 0.0558 - accuracy: 0.0016\n",
      "  10/6501 [..............................] - ETA: 6:17:23 - loss: 0.0514 - accuracy: 0.0016\n",
      "  11/6501 [..............................] - ETA: 6:19:03 - loss: 0.0481 - accuracy: 0.0014\n",
      "  12/6501 [..............................] - ETA: 6:19:38 - loss: 0.0452 - accuracy: 0.0013\n",
      "  13/6501 [..............................] - ETA: 6:17:08 - loss: 0.0427 - accuracy: 0.0014\n",
      "  14/6501 [..............................] - ETA: 6:16:38 - loss: 0.0407 - accuracy: 0.0013\n",
      "  15/6501 [..............................] - ETA: 6:15:31 - loss: 0.0390 - accuracy: 0.0012\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [41]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# For GPU Training, set `use_gpu` to True.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# trainer = Trainer(backend=\"tensorflow\", num_workers=4, use_gpu=True)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m trainer\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m----> 9\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_func_distributed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m trainer\u001b[38;5;241m.\u001b[39mshutdown()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/ray/train/trainer.py:309\u001b[0m, in \u001b[0;36mTrainer.run\u001b[0;34m(self, train_func, config, callbacks, dataset, checkpoint, checkpoint_strategy)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m     iterator \u001b[38;5;241m=\u001b[39m TrainingIterator(\n\u001b[1;32m    300\u001b[0m         backend_executor_actor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend_executor_actor,\n\u001b[1;32m    301\u001b[0m         backend_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend_config,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    307\u001b[0m         run_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_run_dir,\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 309\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m intermediate_result \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[1;32m    310\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m callbacks:\n\u001b[1;32m    311\u001b[0m             callback\u001b[38;5;241m.\u001b[39mprocess_results(intermediate_result)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/ray/train/trainer.py:674\u001b[0m, in \u001b[0;36mTrainingIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_finished():\n\u001b[1;32m    673\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m next_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_with_error_handling\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fetch_next_result\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m next_results \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/ray/train/trainer.py:647\u001b[0m, in \u001b[0;36mTrainingIterator._run_with_error_handling\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_with_error_handling\u001b[39m(\u001b[38;5;28mself\u001b[39m, func: Callable):\n\u001b[1;32m    646\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 647\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TrainingWorkerError:\n\u001b[1;32m    649\u001b[0m         \u001b[38;5;66;03m# Workers have already been restarted.\u001b[39;00m\n\u001b[1;32m    650\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_training(\n\u001b[1;32m    651\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_func,\n\u001b[1;32m    652\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_dir,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    656\u001b[0m             latest_checkpoint_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_manager\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    657\u001b[0m             latest_checkpoint_id)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/ray/train/trainer.py:699\u001b[0m, in \u001b[0;36mTrainingIterator._fetch_next_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;124;03m\"\"\"Fetch next results produced by ``train.report()`` from each worker.\u001b[39;00m\n\u001b[1;32m    688\u001b[0m \n\u001b[1;32m    689\u001b[0m \u001b[38;5;124;03mAssumes ``start_training`` has already been called.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    695\u001b[0m \u001b[38;5;124;03m        returns None.\u001b[39;00m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 699\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend_executor_actor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_next_results\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremote\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    701\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m results \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    702\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/ray/_private/client_mode_hook.py:105\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/ray/worker.py:1756\u001b[0m, in \u001b[0;36mget\u001b[0;34m(object_refs, timeout)\u001b[0m\n\u001b[1;32m   1752\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject_refs\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must either be an object ref \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1753\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor a list of object refs.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1755\u001b[0m \u001b[38;5;66;03m# TODO(ujvl): Consider how to allow user to retrieve the ready objects.\u001b[39;00m\n\u001b[0;32m-> 1756\u001b[0m values, debugger_breakpoint \u001b[38;5;241m=\u001b[39m \u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_objects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1757\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobject_refs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(values):\n\u001b[1;32m   1759\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, RayError):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/ray/worker.py:352\u001b[0m, in \u001b[0;36mWorker.get_objects\u001b[0;34m(self, object_refs, timeout)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    348\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting to call `get` on the value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobject_ref\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    349\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhich is not an ray.ObjectRef.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    351\u001b[0m timeout_ms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(timeout \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 352\u001b[0m data_metadata_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore_worker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_objects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobject_refs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_task_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout_ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m debugger_breakpoint \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (data, metadata) \u001b[38;5;129;01min\u001b[39;00m data_metadata_pairs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from ray.train import Trainer\n",
    "\n",
    "trainer = Trainer(backend=\"tensorflow\", num_workers=1)\n",
    "\n",
    "# For GPU Training, set `use_gpu` to True.\n",
    "# trainer = Trainer(backend=\"tensorflow\", num_workers=4, use_gpu=True)\n",
    "\n",
    "trainer.start()\n",
    "results = trainer.run(train_func_distributed)\n",
    "trainer.shutdown()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
